{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Train.ipynb","private_outputs":true,"provenance":[{"file_id":"1u12CToHKw4iTxR2JysvFdYWO-FFgKtCg","timestamp":1607444068701},{"file_id":"1GqZu6zmCy2vMNMZqO78DDuHvwv_9vJcp","timestamp":1604776545663},{"file_id":"1IzPbxNFQmmSYk9s14L4YjBfUgACn9mW2","timestamp":1593978024316},{"file_id":"1G7NKeneJNyRtcRxLVbbF9jYtRyuTOa-R","timestamp":1592749700622},{"file_id":"https://github.com/satyajitghana/TSAI-DeepVision-EVA4.0/blob/master/Utils/Colab_25GBRAM_GPU.ipynb","timestamp":1592043804148}],"collapsed_sections":["0dWA-BdOJ-W7"],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"4cbgwZWWfWpp"},"source":["## **Dhaka Traffic Detection using YOLOv5**"]},{"cell_type":"markdown","metadata":{"id":"KeZlAaURJzRM"},"source":["## ***Clone YOLOv5 repository***"]},{"cell_type":"code","metadata":{"id":"pafL7Li0jyXW"},"source":["%cd /content/\n","!git clone https://github.com/Morshed-Alam/yolov5.git  # clone repo\n","!pip install -qr yolov5/requirements.txt  # install dependencies (ignore errors)\n","%cd yolov5\n"," \n","import torch\n","from IPython.display import Image, clear_output  # to display images\n","from utils.google_utils import gdrive_download  # to download models/datasets\n"," \n","!rm -r /content/sample_data/\n","clear_output()\n","print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0dWA-BdOJ-W7"},"source":["## ***Download yolo formatted traffic data from google drive***"]},{"cell_type":"code","metadata":{"id":"dbvnLvJXJ_sr"},"source":["%cd /content/\n","!gdown --id 1RNL2AT0UIrmQl7j0Ul01wVO1tKbBO1lG\n","!unzip dataset1.zip; rm dataset1.zip;"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FxK4Uq88Kbs4"},"source":["## ***Define model configuration and architecture***"]},{"cell_type":"markdown","metadata":{"id":"m3Y23Pa-zwCB"},"source":["***Read number of classes from data.yaml***"]},{"cell_type":"code","metadata":{"id":"BSYFok_VKcmY"},"source":["import yaml\n","with open(\"/content/data.yaml\", 'r') as stream:\n","  num_classes = str(yaml.safe_load(stream)['nc'])\n","  print(num_classes)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jJFo-FemKgWv"},"source":["#Customize IPython write file so we can write variables\n","from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","  with open(line, 'w') as f:\n","    f.write(cell.format(**globals()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hSPqgj97JBZK"},"source":["***Modify number of classes***\n","\n","> Other parameters are same as yolov5x.yaml\n","\n"]},{"cell_type":"code","metadata":{"id":"Yxe_DrJBKkZK"},"source":["%%writetemplate /content/yolov5/models/custom_yolov5x.yaml\n","\n","# parameters\n","nc: {num_classes} # Number of classes\n","depth_multiple: 1.33 # model depth multiple\n","width_multiple: 1.25 # layer channel multiple\n","\n","# Anchors\n","anchors:\n"," - [10,13, 16,30, 33,23]  # P3/8\n"," - [30,61, 62,45, 59,119]  # P4/16\n"," - [116,90, 156,198, 373,326]  # P5/32\n","\n","# YOLOv5 backbone\n","backbone:\n","  # [from, number, module, args]\n","  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n","   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n","   [-1, 3, BottleneckCSP, [128]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","   [-1, 9, BottleneckCSP, [256]],\n","   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n","   [-1, 9, BottleneckCSP, [512]],\n","   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n","   [-1, 1, SPP, [1024, [5, 9, 13]]],\n","   [-1, 3, BottleneckCSP, [1024, False]],  # 9\n","  ]\n","\n","# YOLOv5 head\n","head:\n","  [[-1, 1, Conv, [512, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","   [-1, 3, BottleneckCSP, [512, False]],  # 13\n","\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","   [-1, 3, BottleneckCSP, [256, False]],  # 17 (P3/8-small)\n","\n","   [-1, 1, Conv, [256, 3, 2]],\n","   [[-1, 14], 1, Concat, [1]],  # cat head P4\n","   [-1, 3, BottleneckCSP, [512, False]],  # 20 (P4/16-medium)\n","\n","   [-1, 1, Conv, [512, 3, 2]],\n","   [[-1, 10], 1, Concat, [1]],  # cat head P5\n","   [-1, 3, BottleneckCSP, [1024, False]],  # 23 (P5/32-large)\n","\n","   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","  ]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xa3PeWEcJpg5"},"source":["***Specify Hyperparemeters***\n","\n","> Augmentation hyperparameters tuned on PASCAL VOC dataset are used here\n","\n"]},{"cell_type":"code","metadata":{"id":"NKWgpCFqKlTL"},"source":["%%writetemplate /content/yolov5/data/custom_hyp.yaml\n","lr0: 0.01\n","lrf: 0.2\n","momentum: 0.937\n","weight_decay: 0.0005\n","warmup_epochs: 3.0\n","warmup_momentum: 0.8\n","warmup_bias_lr: 0.1\n","box: 0.05\n","cls: 0.5\n","cls_pw: 1.0\n","obj: 1.0\n","obj_pw: 1.0\n","iou_t: 0.20\n","anchor_t: 4.0\n","#anchors: 3.63\n","fl_gamma: 0.0\n","hsv_h: 0.0138\n","hsv_s: 0.664\n","hsv_v: 0.464\n","degrees: 0.373\n","translate: 0.245\n","scale: 0.898\n","shear: 0.602\n","perspective: 0.0\n","flipud: 0.00856\n","fliplr: 0.5\n","mosaic: 1.0\n","mixup: 0.243"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vMBKKu-FKp0Y"},"source":["## ***Train custom YOLOv5 detector***"]},{"cell_type":"markdown","metadata":{"id":"jDDVqYfY9oE4"},"source":["***Log in to wandb***\n"]},{"cell_type":"code","metadata":{"id":"0BUa4MqU9r-T"},"source":["!pip install wandb -qqq\n","import wandb\n","wandb.login"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RxgaxUDLKsfR"},"source":["# train yolov5s on custom data for 40 epochs\n","# time its performance\n","%%time\n","%cd /content/yolov5/\n","!python train.py --img-size 1024 \\\n","                 --batch-size 4 \\\n","                 --epochs 40 \\\n","                 --data ../data.yaml \\\n","                 --cfg ./models/custom_yolov5x.yaml \\\n","                 --weights ./weights/yolov5x.pt \\"],"execution_count":null,"outputs":[]}]}