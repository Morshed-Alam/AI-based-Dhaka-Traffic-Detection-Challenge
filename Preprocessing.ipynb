{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Preprocessing.ipynb","private_outputs":true,"provenance":[{"file_id":"1pi4foPL7Cg0sA7_ri52yu5sd6zjTXU2m","timestamp":1602778265134}],"collapsed_sections":["chhnO8oobQyr","w9VKi9G_L6Xp","Cbt_BTMJeU0b","Ud8eLlhcu6-Q","joWrtBu3VWQr","gYiGNesTl6pv","iiFhIDozx0Pv"]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"chhnO8oobQyr"},"source":["## ***Import neccessay packages***"]},{"cell_type":"code","metadata":{"id":"euZCKcjLbObi"},"source":["import os, glob, shutil\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import random\n","import pandas as pd\n","import plotly.express as px\n","from PIL import Image\n","from google.colab import drive\n","from xml.dom import minidom\n","from IPython.display import clear_output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QlPymajh8onk"},"source":["## ***Data Download***\n","***Data Sources:***\n","> *   3002 Images from dataset released by organizer\n","> *   272 Images from [Dhaka-Traffic repository](https://github.com/Morshed-Alam/Dhaka-Traffic.git)\n","> *   499 Images from 1st round test1 data. (Annotated manually)"]},{"cell_type":"markdown","metadata":{"id":"duv2qKdEbrgG"},"source":["***Download data release by organizer***\n","\n","> Corrected incorrect files manually\n","\n"]},{"cell_type":"code","metadata":{"id":"3OcCpqDBbKB6"},"source":["# Downloading the dataset\n","%cd /content/\n","\n","# Removing unnecessary demo data folder from workspace.\n","!rm -r sample_data\n"," \n","!gdown --id 1CdSorVH5Umf5FbY1FAuIq-UrLxFJlSPz\n","!unzip Final-Train-Dataset.zip; rm Final-Train-Dataset.zip;\n","\n","# Renaming raw data folder to remove space. It makes life a lot easier\n","%mv 'Final Train Dataset' train_data_raw\n","clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MWMPen4pcVXY"},"source":["***Download data released in [Dhaka-Traffic repository](https://github.com/Morshed-Alam/Dhaka-Traffic.git)***"]},{"cell_type":"code","metadata":{"id":"nJ5uYrUYcw4R"},"source":["%cd /content/\n","!curl -L 'https://codeload.github.com/Morshed-Alam/Dhaka-Traffic/zip/v1.0.0' > source.zip; unzip source.zip; rm source.zip\n","clear_output()\n","\n","# Move data to train_data_raw\n","files = glob.glob(f'/content/Dhaka-Traffic-1.0.0/data/*')\n","for file in files:\n","    shutil.move(file, '/content/train_data_raw/')\n","\n","# Remove remaining folders\n","!rm -r /content/Dhaka-Traffic-1.0.0/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wsa6lERVb-Ub"},"source":["***Download Test1 data***"]},{"cell_type":"code","metadata":{"id":"8iXTn0G2C9l6"},"source":["%cd /content/\n","!gdown --id 1AgJ9d7JoNujSucBUlBZPTRga9Yp2G_j_\n","!unzip test1_labeled.zip; rm test1_labeled.zip;\n","clear_output()\n","\n","# Move data to train_data_raw\n","files = glob.glob(f'/content/test1_labeled/*')\n","for file in files:\n","    shutil.move(file, '/content/train_data_raw/')\n","\n","# Remove remaining folder\n","!rm -r /content/test1_labeled"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w9VKi9G_L6Xp"},"source":["## ***Find Images containing lower frequency classes from data***\n","\n","> Frequency = number of vehicles\n","\n"]},{"cell_type":"markdown","metadata":{"id":"_byrkrWxi4hz"},"source":["***Vehicle class labels***"]},{"cell_type":"code","metadata":{"id":"gh-1qYj3PJFR"},"source":["lut={\"ambulance\": 0,\n","     \"army vehicle\": 1,\n","     \"auto rickshaw\": 2,\n","     \"bicycle\": 3,\n","     \"bus\": 4,\n","     \"car\": 5,\n","     \"garbagevan\": 6,\n","     \"human hauler\": 7,\n","     \"minibus\": 8,\n","     \"minivan\": 9,\n","     \"motorbike\": 10,\n","     \"pickup\": 11,\n","     \"policecar\": 12,\n","     \"rickshaw\": 13,\n","     \"scooter\": 14,\n","     \"suv\": 15,\n","     \"taxi\": 16,\n","     \"three wheelers (CNG)\": 17,\n","     \"truck\": 18,\n","     \"van\": 19,\n","     \"wheelbarrow\": 20\n","     }"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lluQMd0LjJ59"},"source":["***Read number of vehicles in each class***"]},{"cell_type":"code","metadata":{"id":"CPMftwXZL_F2"},"source":["xml = glob.glob(f'/content/train_data_raw/*.xml')\n","label_stat = {}\n","for fname in xml:\n","   xmldoc = minidom.parse(fname)\n","   itemlist = xmldoc.getElementsByTagName('object')\n","   for item in itemlist:\n","        # get class label\n","        classid =  (item.getElementsByTagName('name')[0]).firstChild.data\n","        if classid in lut:\n","            try: \n","               label_stat[classid].extend([fname])\n","            except:\n","               label_stat[classid] = [fname]\n","        else:\n","            label_str = \"-1\"\n","            print (\"warning: label '%s' not in look-up table for file '%s'\" % classid, fname )\n","\n","label_stat = {k: v for k, v in sorted(label_stat.items(), key=lambda item: len(item[1]))}\n","\n","for key in label_stat.keys():\n","    print(key, \" :\", len(label_stat[key]))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9cGh-sTGj7S5"},"source":["***List xml files containing lower frequency classes***\n"]},{"cell_type":"code","metadata":{"id":"TdQ8zeFsa3y4"},"source":["num = 11                                 # Number of low frequency classes to which we apply augmentation\n","minor_class_list = []\n","i = 0\n","for value in label_stat.values():\n","    if i in range(num):\n","        minor_class_list.extend(value)\n","        i += 1\n","\n","minor_class_set = set(minor_class_list)\n","minor_class_list = list(minor_class_set)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vKt2bBBdpWyq"},"source":["## ***Apply augmentation to increase the image items***\n","We only apply the augmentation to low frequency classes of our training set not to validation set"]},{"cell_type":"markdown","metadata":{"id":"bUkMyjLop_g0"},"source":["[***Download augmentation repository from github***](https://github.com/Morshed-Alam/DataAugmentation.git)"]},{"cell_type":"code","metadata":{"id":"cKCP6qalpiox"},"source":["%cd /content/\n","!git clone https://github.com/Morshed-Alam/DataAugmentation.git"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BxB8gJD9toT1"},"source":["***List of files containing low frequency classes***"]},{"cell_type":"code","metadata":{"id":"Wg1-3GTqtw5Z"},"source":["# Reading train Image file paths\n","formats = ['jpg', 'jpeg', 'JPG', 'png', 'PNG']\n","image_file_list = []\n","for file in minor_class_list:\n","    for format in formats:\n","        image_file_list.extend(glob.glob(f'{file[:-4]}.{format}'))\n","\n","# Reading train xml label file paths\n","label_file_list_xml = minor_class_list\n","\n","print(f'Image files found: {len(image_file_list)} \\nLabel files found: { len(label_file_list_xml)}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xz8XkR_d0bF2"},"source":["***Create augment output directory***\n","\n","> Image and xml file will be saved to these directories after augmentation\n","\n"]},{"cell_type":"code","metadata":{"id":"eFj5wUMax86n"},"source":["augment_output_dirs = ['/content/horizontalflip', '/content/translate', '/content/scale', '/content/rotate', '/content/shear', '/content/randomhsv']\n","\n","for dir in augment_output_dirs:\n","    if os.path.exists(dir):\n","       print(f'Directory {dir} already exists !')\n","    else: \n","       os.makedirs(dir)\n","       print(f\"Directory {dir} is created successfully!\") \n","       "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P-4jlj7bqsLU"},"source":["***Create augmentation objects***\n","\n","> We apply following augmentation\n","\n","*   Horizontal flip\n","*   Scale\n","*   Translation\n","*   Rotation\n","*   Random HSV\n","*   Shear\n","\n"]},{"cell_type":"code","metadata":{"id":"Ls99B63zqxIu"},"source":["%cd /content/DataAugmentation/\n","import augmentation as ag\n","import data_aug as da\n","\n","aug_hf = da.HorizontalFlip()\n","aug_s = da.Scale(0.898)\n","aug_t = da.Translate(0.245)\n","aug_r = da.Rotate(37)\n","aug_hsv = da.RandomHSV(hue=2, saturation=66, brightness=20)\n","aug_shear = da.Shear(0.602)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q4IxXeZOtRdd"},"source":["***Apply augmentation***"]},{"cell_type":"code","metadata":{"id":"7jeEQRbltVkq"},"source":["# Horizontal flip\n","ag.apply_aug(image_file_list, augment_output_dirs[0], aug_hf, lut)\n"," \n","# Translate\n","ag.apply_aug(image_file_list, augment_output_dirs[1], aug_t, lut)\n"," \n","# Scale\n","ag.apply_aug(image_file_list, augment_output_dirs[2], aug_s, lut)\n"," \n","# Rotation\n","ag.apply_aug(image_file_list, augment_output_dirs[3], aug_r, lut)\n"," \n","# Shear\n","ag.apply_aug(image_file_list, augment_output_dirs[4], aug_shear, lut)\n"," \n","# Random HSV\n","ag.apply_aug(image_file_list, augment_output_dirs[5], aug_hsv, lut)\n","\n","clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wrHbieWcBr0n"},"source":["***Testing correctness of augmentation***"]},{"cell_type":"code","metadata":{"id":"zS5BP0ILBuKj"},"source":["%cd /content/DataAugmentation/\n","from bbox_util import draw_rect\n","from augmentation import xml2array\n"," \n","formats = ['jpg', 'jpeg', 'JPG', 'png', 'PNG']\n","for i in range(6):\n","   path = augment_output_dirs[i]+'/'+os.path.split(augment_output_dirs[i])[1]+'_'\n","   img_files = []\n","   for format in formats:\n","       img_files.extend(glob.glob(f'{path}*.{format}'))\n","   # change index to see other image\n","   img_file = img_files[1]\n","   img = cv2.imread(img_file)\n","   bbox = xml2array(os.path.splitext(img_file)[0]+'.xml', lut)\n","   an_img = draw_rect(img, bbox)\n","   original_img_file = '/content/train_data_raw/'+img_file.replace(path, '')\n","   original_img = cv2.imread(original_img_file)\n","   original_bbox = xml2array(os.path.splitext(original_img_file)[0]+'.xml', lut)\n","   original_an_img = draw_rect(original_img, original_bbox)\n"," \n","   plt.figure(i, figsize=(12,6))\n","   plt.subplot(121)\n","   plt.imshow(an_img)\n","   plt.title(os.path.split(img_file)[1])\n"," \n","   plt.subplot(122)\n","   plt.imshow(original_an_img)\n","   plt.title(os.path.split(original_img_file)[1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8v3ZR7yF2uoi"},"source":["***Move all augmentation output to train_data_raw folder***"]},{"cell_type":"code","metadata":{"id":"I0tT44EH22m9"},"source":["for dir in augment_output_dirs:\n","    files = os.listdir(dir)\n","    for file in files:\n","        shutil.move(dir+'/'+file, '/content/train_data_raw/'+file)\n","    os.rmdir(dir)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Cbt_BTMJeU0b"},"source":["<a id=\"5\"></a>\n","## ***Train and Validation Split***\n","For training the model and evaluating at the same time, we will split the whole training dataset into a train and validation set. We will be using $80-20$ dividion rule for the train and validation split. "]},{"cell_type":"code","metadata":{"id":"Hia7j0TxONcy"},"source":["# Reading Image file paths\n","formats = ['jpg', 'jpeg', 'JPG', 'png', 'PNG']\n","image_file_list = []\n","for format in formats:\n","    image_file_list.extend(glob.glob(f'/content/train_data_raw/*.{format}'))\n","\n","# Reading xml label file paths\n","label_file_list_xml = glob.glob(f'/content/train_data_raw/*.xml')\n","\n","print(f'Image files found: {len(image_file_list)} \\nLabel files found: { len(label_file_list_xml)}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NqKag3boftfU"},"source":["random.seed(1500)\n","\n","#randomply selecting the index of the files\n","valid_set_index = random.sample(range(len(image_file_list)), 1000)\n","len(set(image_file_list)), len(set(label_file_list_xml)), len(valid_set_index)\n","\n","image_file_list = sorted(image_file_list)\n","label_file_list_xml = sorted(label_file_list_xml)\n","\n","# sanity check of the image files and labels being in the same order\n","print('Checking files concurrency')\n","print(image_file_list[:5])\n","print(label_file_list_xml[:5])\n","\n","# code to separate train and validation set\n","valid_selected_images = []\n","valid_selected_labels = []\n","\n","for index in range(len(valid_set_index)): \n","    valid_selected_images.append(image_file_list[index])\n","    valid_selected_labels.append(label_file_list_xml[index])\n","\n","print('\\n\\nChecking files concurrency in validation set')\n","print(valid_selected_images[-5:])\n","print(valid_selected_labels[-5:])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VreBCd8yh607"},"source":["# Creating required directories\n","dir = '/content/valid/'\n","\n","if os.path.exists(dir):\n","    print(f'Directory {dir} already exists !')\n","else: \n","    os.makedirs(dir)\n","    print(f\"Directory {dir} is created successfully!\") \n","\n","\n","for idx in range(len(valid_selected_images)):\n","    # moving image files to valid\n","    mypath = valid_selected_images[idx]\n","    if os.path.exists(mypath):\n","        filename = mypath.split('/')[-1]\n","        shutil.move(mypath , dir + filename)\n","    else:\n","        print(f'{mypath} not found')\n","        \n","    # moving label files to valid\n","    mypath = valid_selected_labels[idx]\n","    if os.path.exists(mypath):\n","        filename = mypath.split('/')[-1]\n","        shutil.move(mypath , dir + filename)\n","    else:\n","        print(f'{mypath} not found')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kcCnDR8zzVkK"},"source":["# Rename train_data_raw to train\n","%mv /content/train_data_raw /content/train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VVouoiP7NG8d"},"source":["# Reading remaining train Image file paths\n","formats = ['jpg', 'jpeg', 'JPG', 'png', 'PNG']\n","image_file_list = []\n","for format in formats:\n","    image_file_list.extend(glob.glob(f'/content/train/*.{format}'))\n","\n","# Reading xml label file paths\n","label_file_list_xml = glob.glob(f'/content/train/*.xml')\n","\n","print(f'Image files found: {len(image_file_list)} \\nLabel files found: { len(label_file_list_xml)}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-gyC9HkkEz00"},"source":["<a id=\"3\"></a>\n","## ***Convert .xml  to .txt***"]},{"cell_type":"markdown","metadata":{"id":"EMCNNMpp7Kjg"},"source":["***Define function for xml to txt conversion***"]},{"cell_type":"code","metadata":{"id":"zYo_cAgPMTa2"},"source":["# Track number of labels in each class\n","label_count ={}\n","\n","# Normalize bounding box\n","def convert_coordinates(size, box):\n","    \"\"\"\n","    This function converts the coordinates. \n","    box: (xmin, xmax, ymin, ymax)\n","    size: (width, height)\n"," \n","    returns a touple where (x, y, height, width) of the boundary box\n","    \"\"\"\n","    dw = 1./(size[0])\n","    dh = 1./(size[1])\n","    x = (box[0] + box[1])/2.0 - 1\n","    y = (box[2] + box[3])/2.0 - 1\n","    w = box[1] - box[0]\n","    h = box[3] - box[2]\n","    x = x*dw\n","    w = w*dw\n","    y = y*dh\n","    h = h*dh\n","    return (x,y,w,h)\n"," \n","# Convert PASCAL VOC xml format to YOLO txt format\n","def convert_xml2yolo(filelist, lut ):\n","    \"\"\"\n","    filelist: list of .xml file paths to convert to .txt file\n","    lut: a dictionary containing class_name to class_index mapping\n","    \"\"\"\n","    for fname in filelist:\n","        xmldoc = minidom.parse(fname)\n","        fname_out = (fname[:-4]+'.txt')\n"," \n","        with open(fname_out, \"w\") as f:\n","            print(f'processing{fname}')\n"," \n","            itemlist = xmldoc.getElementsByTagName('object')\n","            size = xmldoc.getElementsByTagName('size')[0]\n","            width = int((size.getElementsByTagName('width')[0]).firstChild.data)\n","            height = int((size.getElementsByTagName('height')[0]).firstChild.data)\n"," \n","            for item in itemlist:\n","                # get class label\n","                classid =  (item.getElementsByTagName('name')[0]).firstChild.data\n","                if classid in lut:\n","                    label_str = str(lut[classid])\n","                else:\n","                    label_str = \"-1\"\n","                    print (\"warning: label '%s' not in look-up table for file '%s'\" % classid, fname )\n","                # get bbox coordinates\n","                xmin = ((item.getElementsByTagName('bndbox')[0]).getElementsByTagName('xmin')[0]).firstChild.data\n","                ymin = ((item.getElementsByTagName('bndbox')[0]).getElementsByTagName('ymin')[0]).firstChild.data\n","                xmax = ((item.getElementsByTagName('bndbox')[0]).getElementsByTagName('xmax')[0]).firstChild.data\n","                ymax = ((item.getElementsByTagName('bndbox')[0]).getElementsByTagName('ymax')[0]).firstChild.data\n","                b = (float(xmin), float(xmax), float(ymin), float(ymax))\n","                bb = convert_coordinates((width,height), b)\n","                #print(bb)\n","                x = bb[0]\n","                y = bb[1]\n","                w = bb[2]\n","                h = bb[3]\n","                if x > 1.0: print('Error')\n","                if y > 1.0: print('Error')\n","                if w > 1.0: print('Error')\n","                if h > 1.0: print('Error')\n"," \n","                label_count[classid] = label_count.get(classid, 0) + 1\n"," \n","                f.write(label_str + \" \" + \" \".join([(\"%.11f\" % a) for a in bb]) + '\\n')\n","        # print (\"wrote %s\" % fname_out)\n","        clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lE0TCNlVPY-c"},"source":["***Convert training xml file to txt file***"]},{"cell_type":"code","metadata":{"id":"1dJTNvisMLco"},"source":["# Reading train Image file paths\n","formats = ['jpg', 'jpeg', 'JPG', 'png', 'PNG']\n","image_file_list = []\n","for format in formats:\n","    image_file_list.extend(glob.glob(f'/content/train/*.{format}'))\n"," \n","# Reading train XML label file paths\n","label_file_list_xml = glob.glob('/content/train/*.xml')\n"," \n","print(f'Image files found: {len(image_file_list)} \\nLabel files found: { len(label_file_list_xml)}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-dZsVaW3LWsO"},"source":["# Converting  train .xml file to .txt file\n","convert_xml2yolo(label_file_list_xml, lut)\n","label_file_list_txt = glob.glob('/content/train/*.txt')\n","print(f'XML --> TXT files: {len(label_file_list_txt)}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JTfW7OJ7TfRZ"},"source":["# Print number of vehicles per classes in train\n","train_label_count = label_count  # used to visualize\n","label_count = {}\n","train_label_count"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s1nqqpaH7WUw"},"source":["# Remove xml files\n","%rm -r /content/train/*.xml"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YBg9_4KkCNTY"},"source":["# Convert to YOLOv5 data format\n","%mkdir /content/train/images /content/train/labels\n","for file in image_file_list:\n","    shutil.move(file, '/content/train/images/'+os.path.split(file)[1])\n","for file in label_file_list_txt:\n","    shutil.move(file, '/content/train/labels/'+os.path.split(file)[1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tap0djJf6NUE"},"source":["***Convert validation xml file to txt file***"]},{"cell_type":"code","metadata":{"id":"xSx4Broi6Tkd"},"source":["# Reading valid Image file paths\n","formats = ['jpg', 'jpeg', 'JPG', 'png', 'PNG']\n","image_file_list = []\n","for format in formats:\n","    image_file_list.extend(glob.glob(f'/content/valid/*.{format}'))\n"," \n","# Reading valid XML label file paths\n","label_file_list_xml = glob.glob('/content/valid/*.xml')\n"," \n","print(f'Image files found: {len(image_file_list)} \\nLabel files found: { len(label_file_list_xml)}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dxUXOB3K6jCV"},"source":["# Converting valid .xml file to .txt file\n","convert_xml2yolo(label_file_list_xml, lut)\n","label_file_list_txt = glob.glob('/content/valid/*.txt')\n","print(f'XML --> TXT files: {len(label_file_list_txt)}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HyRyC6p16wRm"},"source":["# Print number of vehicles per classes in valid\n","valid_label_count = label_count # used to visualize\n","valid_label_count"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"csMByuOp7p1d"},"source":["# Remove xml files\n","%rm -r /content/valid/*.xml"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PMAJpVBKDpoL"},"source":["# Convert to YOLOv5 data format\n","%mkdir /content/valid/images /content/valid/labels\n","for file in image_file_list:\n","    shutil.move(file, '/content/valid/images/'+os.path.split(file)[1])\n","for file in label_file_list_txt:\n","    shutil.move(file, '/content/valid/labels/'+os.path.split(file)[1])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ud8eLlhcu6-Q"},"source":["## ***Data Visualization***\n","Let us have a look at the existance of the labels in the dataset."]},{"cell_type":"markdown","metadata":{"id":"hmwcdgm4TVl3"},"source":["***Train data visualization***"]},{"cell_type":"code","metadata":{"id":"kV-PUUqquxmh"},"source":["# DataFrame Generation\n","df = pd.DataFrame({'labels': train_label_count.keys(), 'count': train_label_count.values()})\n","df.columns = ['labels', 'count']\n","df.sort_values(['count'], ascending = False, inplace =True)\n","df.head()\n","\n","# Plotting\n","fig = px.bar(df, x=\"labels\", y='count',  color=\"count\",\n","    orientation='v', \n","    title='Frequency of the Labels in Train data', \n","    color_continuous_scale=px.colors.sequential.Viridis_r\n",")\n","fig.update_layout(title_x=0.5, xaxis_title = 'Labels', yaxis_title = 'Label Count')\n","fig.update_xaxes(tickangle=60)\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ad4B9APcTaUk"},"source":["***Valid data visualization***"]},{"cell_type":"code","metadata":{"id":"sQ3zZSR6S8vm"},"source":["import pandas as pd\n","import plotly.express as px\n","\n","# DataFrame Generation\n","df = pd.DataFrame({'labels': valid_label_count.keys(), 'count': valid_label_count.values()})\n","df.columns = ['labels', 'count']\n","df.sort_values(['count'], ascending = False, inplace =True)\n","df.head()\n","\n","# Plotting\n","fig = px.bar(df, x=\"labels\", y='count',  color=\"count\",\n","    orientation='v', \n","    title='Frequency of the Labels in valid data', \n","    color_continuous_scale=px.colors.sequential.Viridis_r\n",")\n","fig.update_layout(title_x=0.5, xaxis_title = 'Labels', yaxis_title = 'Label Count')\n","fig.update_xaxes(tickangle=60)\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"joWrtBu3VWQr"},"source":["<a id=\"4\"></a>\n","## ***Resizing all the Images***"]},{"cell_type":"markdown","metadata":{"id":"ORo-Z2yC8SYl"},"source":["***Define resize function***"]},{"cell_type":"code","metadata":{"id":"szOyEAsFZUKv"},"source":["def resize_images(file_list, width = 1024, height = 1024, overwrite = True, save_dir = ''):\n","    total_files = len(file_list)\n","    idx = 1\n","    for path in file_list:\n","        img = Image.open(path)\n","        img_resized = img.resize((width, height), Image.ANTIALIAS)\n","        if overwrite:\n","            img_resized.save(path)\n","            filename = path.split('/')[-1] \n","            print(f\"{idx}/{total_files}: {filename} {img.size}--> ({width}x{height})\")\n","        else:\n","            filename = path.split('/')[-1]\n","            img_resized.save(save_dir + filename)\n","            print(f'{filename} saved to {save_dir}')\n","        idx +=1\n","    clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5O-AGGHu8eok"},"source":["***Resize train images***"]},{"cell_type":"code","metadata":{"id":"PtPMhtlr81Zw"},"source":["# Reading train Image file paths\n","formats = ['jpg', 'jpeg', 'JPG', 'png', 'PNG']\n","image_file_list = []\n","for format in formats:\n","    image_file_list.extend(glob.glob(f'/content/train/images/*.{format}'))\n","\n","print(f'Image files found: {len(image_file_list)}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yYVfpex0bino"},"source":["resize_images(image_file_list , overwrite= True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OzruPu-c8s1F"},"source":["***Resize valid images***"]},{"cell_type":"code","metadata":{"id":"AlyqOev28xTJ"},"source":["# Reading valid Image file paths\n","formats = ['jpg', 'jpeg', 'JPG', 'png', 'PNG']\n","image_file_list = []\n","for format in formats:\n","    image_file_list.extend(glob.glob(f'/content/valid/images/*.{format}'))\n","\n","print(f'Image files found: {len(image_file_list)}')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ig9wruVA9Xfn"},"source":["resize_images(image_file_list , overwrite= True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sB-TYEDi55q3"},"source":["## ***Adding blur and dark augmented images to train***\n","\n","> 537 images are selected by random shuffling from train data released by organizer and blur and dark augmentation is applied to them using roboflow platform\n","\n"]},{"cell_type":"code","metadata":{"id":"SRERbnQs8Yfn"},"source":["%cd /content/\n","!gdown --id 19b_nmsDZrJAWaL0AArN5_lQ0ftYWOL3m\n","!unzip roboflow.zip; rm roboflow.zip;\n","clear_output()\n","\n","# Move images to trian\n","files = glob.glob(f'/content/roboflow/images/*')\n","for file in files:\n","    shutil.move(file, '/content/train/images/')\n","\n","# Move labels to train\n","files = glob.glob(f'/content/roboflow/labels/*')\n","for file in files:\n","    shutil.move(file, '/content/train/labels/')\n","\n","# Remove roboflow folder\n","!rm -r /content/roboflow"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LAGgBK9u-gPF"},"source":["## ***Finally copy valid data to train***\n","\n","> To increase train data\n","\n"]},{"cell_type":"code","metadata":{"id":"kBme2QkS-xvQ"},"source":["# Copy images to train\n","files = glob.glob(f'/content/valid/images/*')\n","for file in files:\n","    shutil.copy(file, '/content/train/images/')\n","\n","# Copy labels to train\n","files = glob.glob(f'/content/valid/labels/*')\n","for file in files:\n","    shutil.copy(file, '/content/train/labels/')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N6rjvl03BfJp"},"source":["## ***Dataset statistics***"]},{"cell_type":"code","metadata":{"id":"2orYpphDBwJL"},"source":["train_imgs = glob.glob(f'/content/train/images/*')\n","train_labels = glob.glob(f'/content/train/labels/*')\n","valid_imgs = glob.glob(f'/content/valid/images/*')\n","valid_labels = glob.glob(f'/content/valid/labels/*')\n","print('Train images: ' + str(len(train_imgs)))\n","print('Train labesl: ' + str(len(train_labels)))\n","print('Valid images: ' + str(len(valid_imgs)))\n","print('Valid labels: ' + str(len(valid_labels)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gYiGNesTl6pv"},"source":["<a id=\"6\"></a>\n","## ***Creating data.yaml file***"]},{"cell_type":"code","metadata":{"id":"H8KSTK3ZPKDx"},"source":["#Customize IPython write file so we can write variables\n","from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","  with open(line, 'w') as f:\n","    f.write(cell.format(**globals()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EnOqsfUEYuWR"},"source":["# list of labels\n","names = [k for k, v in lut.items()]\n","names"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"suKJ19TUQgwZ"},"source":["%%writetemplate /content/data.yaml\n","\n","train: ../train/images\n","val: ../valid/images\n","\n","nc: 21\n","names: {names}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iiFhIDozx0Pv"},"source":["<a id=\"7\"></a>\n","## ***Saving the Processed Dataset***"]},{"cell_type":"code","metadata":{"id":"wxY-Cdol9Kih"},"source":["# Zip all to dataset.zip\n","%cd /content/\n","!zip -r dataset.zip train valid data.yaml\n","clear_output()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AZOFjg_56PvJ"},"source":["# Mount google drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9R4BCpEGKGhF"},"source":["# Copy dataset.zip to drive\n","!cp dataset.zip '/content/drive/My Drive/Colab Notebooks/dataset/'"],"execution_count":null,"outputs":[]}]}